{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca3b25398e465b0123cf513426ccf1713f7d2277"
   },
   "source": [
    "Version1 : best LB score\n",
    "\n",
    "Version 2:  Increase to 400 rounds\n",
    "\n",
    "Version 4 : 0.5 wowfattie + 0.25 BiGRU + 0.25 Elmo\n",
    "\n",
    "Version 5 : 0.4 wow fattie + 0.3 EMA + 0.15 BiGRU + 0.15 Elmo \n",
    "\n",
    "Version 6: change to 700 rounds\n",
    "\n",
    "Version 7 : Change to 500 rounds * 10 folds --> not much improve in the local CV score \n",
    "\n",
    "Version 9 Change to 700 rounds * 5 fold  AND  0.5 wow fattie + 0.4 EMA + 0.10 BiGRU + 0.10 Elmo ==> save oof and pred file as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "58a441e669a0f644151d7acd6ae441dc5ec0f3f3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "cffede7830e2c98ed4119b1c379df5c5b751a7f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pred_EMA.np.npy', 'custom.css', '__results__.html', 'submission.csv', '__output__.json', '__notebook__.ipynb', 'oof_EMA.np.npy']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input/ema-19032019\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "6fb087a7824b8b3be496d760dd76bf8c232f3b92"
   },
   "outputs": [],
   "source": [
    "# # train_EMA = np.load('../input/ema-19032019/oof_EMA.np.npy')\n",
    "# train_EMA  =np.load('../input/ensembling-ndsc/ensembling_v2/oof_Elmo.np.npy') \n",
    "# train = pd.read_csv('../input/ndsc-beginner/train.csv')\n",
    "# y = train['Category']\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# oof_ = [np.argmax(preds) for preds in train_EMA]\n",
    "# print(\"CV score: {:<8.5f}\".format(accuracy_score(y, oof_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "97760a685b401e47295aea6f233d6d3c3e1ba1bc"
   },
   "outputs": [],
   "source": [
    "train_wowfattie = np.load('../input/ensembling-ndsc/ensembling_v2/oof_prob1.npy') #0.79 acc - 0.758 LB\n",
    "train_EMA = np.load('../input/ema-19032019/oof_EMA.np.npy') #0.77 acc \n",
    "train_BiGRU = np.load('../input/ensembling-ndsc/ensembling_v2/oof_Bi-GRU-LSTM-CNN-Poolings-Fasttext.np.npy') #0.73 acc\n",
    "train_elmo = np.load('../input/ensembling-ndsc/ensembling_v2/oof_Elmo.np.npy') #0.71 acc \n",
    "\n",
    "test_wowfattie = np.load('../input/ensembling-ndsc/ensembling_v2/pred_wowfattie.npy')\n",
    "test_EMA  =np.load('../input/ema-19032019/pred_EMA.np.npy')\n",
    "test_BiGRU = np.load('../input/ensembling-ndsc/ensembling_v2/pred_BiGRU.npy')\n",
    "test_elmo = np.load('../input/ensembling-ndsc/ensembling_v2/pred_elmo.npy')\n",
    "\n",
    "#------------------------------------\n",
    "train_arr = np.zeros((666615, 58))\n",
    "test_arr = np.zeros((172402, 58))\n",
    "\n",
    "train_arr += 0.5*np.squeeze(train_wowfattie)\n",
    "train_arr += 0.3*np.squeeze(train_EMA)\n",
    "train_arr += 0.10*np.squeeze(train_BiGRU)\n",
    "train_arr += 0.10*np.squeeze(train_elmo)\n",
    "\n",
    "test_arr += 0.5*np.squeeze(test_wowfattie)\n",
    "test_arr += 0.3*np.squeeze(test_EMA)\n",
    "test_arr += 0.10*np.squeeze(test_BiGRU)\n",
    "test_arr += 0.10*np.squeeze(test_elmo)\n",
    "\n",
    "train_arr = pd.DataFrame(train_arr ,columns=['class_'+str(i) for i in range(58)])\n",
    "test_arr = pd.DataFrame(test_arr ,columns=['class_'+str(i) for i in range(58)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5d866fc5ac9e10ab07ae79704f0ae3551d4aa3e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172402, 58)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_BiGRU.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "9f55853a9a19e65315de725bb5efd8bb9dd5e95f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(666615, 58)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wowfattie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "9090941dcf772ab97ee9b0190b1afdd19f06f913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(666615, 4)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../input/ndsc-beginner/train.csv')\n",
    "print(train.shape)\n",
    "test = pd.read_csv('../input/ndsc-beginner/test.csv')\n",
    "y = train['Category']\n",
    "train = train[['itemid']]\n",
    "test = test[['itemid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "949e2abf7981f89fcb965b325ee65018439b62c1"
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train,train_arr],axis= 1, sort = False)\n",
    "test = pd.concat([test,test_arr], axis =1 ,sort = False )\n",
    "\n",
    "del train_elmo,train_wowfattie\n",
    "del test_elmo,test_wowfattie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "3d4f2aeec2d9b071318433c564379d0f7f644bcc"
   },
   "outputs": [],
   "source": [
    "# del sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "96d831f2027cf1409c7d022d19f634d1b3657242",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itemid', 'class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9', 'class_10', 'class_11', 'class_12', 'class_13', 'class_14', 'class_15', 'class_16', 'class_17', 'class_18', 'class_19', 'class_20', 'class_21', 'class_22', 'class_23', 'class_24', 'class_25', 'class_26', 'class_27', 'class_28', 'class_29', 'class_30', 'class_31', 'class_32', 'class_33', 'class_34', 'class_35', 'class_36', 'class_37', 'class_38', 'class_39', 'class_40', 'class_41', 'class_42', 'class_43', 'class_44', 'class_45', 'class_46', 'class_47', 'class_48', 'class_49', 'class_50', 'class_51', 'class_52', 'class_53', 'class_54', 'class_55', 'class_56', 'class_57']\n",
      "Starting training...\n",
      "(666615, 59)\n",
      "fold 0 \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's multi_error: 0.325327\n",
      "[20]\tvalid_0's multi_error: 0.21445\n",
      "[30]\tvalid_0's multi_error: 0.204071\n",
      "[40]\tvalid_0's multi_error: 0.201213\n",
      "[50]\tvalid_0's multi_error: 0.200208\n",
      "[60]\tvalid_0's multi_error: 0.199196\n",
      "[70]\tvalid_0's multi_error: 0.198356\n",
      "[80]\tvalid_0's multi_error: 0.197726\n",
      "[90]\tvalid_0's multi_error: 0.197284\n",
      "[100]\tvalid_0's multi_error: 0.196624\n",
      "[110]\tvalid_0's multi_error: 0.196271\n",
      "[120]\tvalid_0's multi_error: 0.195829\n",
      "[130]\tvalid_0's multi_error: 0.195341\n",
      "[140]\tvalid_0's multi_error: 0.195034\n",
      "[150]\tvalid_0's multi_error: 0.194554\n",
      "[160]\tvalid_0's multi_error: 0.194172\n",
      "[170]\tvalid_0's multi_error: 0.193579\n",
      "[180]\tvalid_0's multi_error: 0.193197\n",
      "[190]\tvalid_0's multi_error: 0.192844\n",
      "[200]\tvalid_0's multi_error: 0.192402\n",
      "[210]\tvalid_0's multi_error: 0.191989\n",
      "[220]\tvalid_0's multi_error: 0.191674\n",
      "[230]\tvalid_0's multi_error: 0.191494\n",
      "[240]\tvalid_0's multi_error: 0.191907\n",
      "[250]\tvalid_0's multi_error: 0.191457\n",
      "[260]\tvalid_0's multi_error: 0.191277\n",
      "[270]\tvalid_0's multi_error: 0.191037\n",
      "[280]\tvalid_0's multi_error: 0.190722\n",
      "[290]\tvalid_0's multi_error: 0.190459\n",
      "[300]\tvalid_0's multi_error: 0.190519\n",
      "[310]\tvalid_0's multi_error: 0.190257\n",
      "[320]\tvalid_0's multi_error: 0.190122\n",
      "[330]\tvalid_0's multi_error: 0.189934\n",
      "[340]\tvalid_0's multi_error: 0.189732\n",
      "[350]\tvalid_0's multi_error: 0.189612\n",
      "[360]\tvalid_0's multi_error: 0.189402\n",
      "[370]\tvalid_0's multi_error: 0.18932\n",
      "[380]\tvalid_0's multi_error: 0.18926\n",
      "[390]\tvalid_0's multi_error: 0.189297\n",
      "[400]\tvalid_0's multi_error: 0.189162\n",
      "[410]\tvalid_0's multi_error: 0.189942\n",
      "[420]\tvalid_0's multi_error: 0.189739\n",
      "[430]\tvalid_0's multi_error: 0.189814\n",
      "[440]\tvalid_0's multi_error: 0.189814\n",
      "[450]\tvalid_0's multi_error: 0.189462\n",
      "[460]\tvalid_0's multi_error: 0.189327\n",
      "[470]\tvalid_0's multi_error: 0.189754\n",
      "[480]\tvalid_0's multi_error: 0.189499\n",
      "[490]\tvalid_0's multi_error: 0.189275\n",
      "[500]\tvalid_0's multi_error: 0.189095\n",
      "[510]\tvalid_0's multi_error: 0.18902\n",
      "[520]\tvalid_0's multi_error: 0.188765\n",
      "[530]\tvalid_0's multi_error: 0.188577\n",
      "[540]\tvalid_0's multi_error: 0.188435\n",
      "[550]\tvalid_0's multi_error: 0.188322\n",
      "[560]\tvalid_0's multi_error: 0.188075\n",
      "[570]\tvalid_0's multi_error: 0.187932\n",
      "[580]\tvalid_0's multi_error: 0.188045\n",
      "[590]\tvalid_0's multi_error: 0.187932\n",
      "[600]\tvalid_0's multi_error: 0.189649\n",
      "[610]\tvalid_0's multi_error: 0.189627\n",
      "[620]\tvalid_0's multi_error: 0.198071\n",
      "[630]\tvalid_0's multi_error: 0.243772\n",
      "[640]\tvalid_0's multi_error: 0.255696\n",
      "[650]\tvalid_0's multi_error: 0.347682\n",
      "[660]\tvalid_0's multi_error: 0.383566\n",
      "[670]\tvalid_0's multi_error: 0.399795\n",
      "[680]\tvalid_0's multi_error: 0.454757\n",
      "[690]\tvalid_0's multi_error: 0.420253\n",
      "Early stopping, best iteration is:\n",
      "[593]\tvalid_0's multi_error: 0.18782\n",
      "(666615, 58)\n",
      "(172402, 58)\n",
      "fold 1 \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's multi_error: 0.326044\n",
      "[20]\tvalid_0's multi_error: 0.21384\n",
      "[30]\tvalid_0's multi_error: 0.20283\n",
      "[40]\tvalid_0's multi_error: 0.200115\n",
      "[50]\tvalid_0's multi_error: 0.199036\n",
      "[60]\tvalid_0's multi_error: 0.197851\n",
      "[70]\tvalid_0's multi_error: 0.197251\n",
      "[80]\tvalid_0's multi_error: 0.196696\n",
      "[90]\tvalid_0's multi_error: 0.196276\n",
      "[100]\tvalid_0's multi_error: 0.195601\n",
      "[110]\tvalid_0's multi_error: 0.195061\n",
      "[120]\tvalid_0's multi_error: 0.194656\n",
      "[130]\tvalid_0's multi_error: 0.194266\n",
      "[140]\tvalid_0's multi_error: 0.194026\n",
      "[150]\tvalid_0's multi_error: 0.193643\n",
      "[160]\tvalid_0's multi_error: 0.193396\n",
      "[170]\tvalid_0's multi_error: 0.192796\n",
      "[180]\tvalid_0's multi_error: 0.192398\n",
      "[190]\tvalid_0's multi_error: 0.192173\n",
      "[200]\tvalid_0's multi_error: 0.191746\n",
      "[210]\tvalid_0's multi_error: 0.191468\n",
      "[220]\tvalid_0's multi_error: 0.191161\n",
      "[230]\tvalid_0's multi_error: 0.190898\n",
      "[240]\tvalid_0's multi_error: 0.190523\n",
      "[250]\tvalid_0's multi_error: 0.190366\n",
      "[260]\tvalid_0's multi_error: 0.190171\n",
      "[270]\tvalid_0's multi_error: 0.189931\n",
      "[280]\tvalid_0's multi_error: 0.189893\n",
      "[290]\tvalid_0's multi_error: 0.189601\n",
      "[300]\tvalid_0's multi_error: 0.189428\n",
      "[310]\tvalid_0's multi_error: 0.189286\n",
      "[320]\tvalid_0's multi_error: 0.189226\n",
      "[330]\tvalid_0's multi_error: 0.189091\n",
      "[340]\tvalid_0's multi_error: 0.188761\n",
      "[350]\tvalid_0's multi_error: 0.188603\n",
      "[360]\tvalid_0's multi_error: 0.188536\n",
      "[370]\tvalid_0's multi_error: 0.188438\n",
      "[380]\tvalid_0's multi_error: 0.188311\n",
      "[390]\tvalid_0's multi_error: 0.188356\n",
      "[400]\tvalid_0's multi_error: 0.188206\n",
      "[410]\tvalid_0's multi_error: 0.188018\n",
      "[420]\tvalid_0's multi_error: 0.187876\n",
      "[430]\tvalid_0's multi_error: 0.187673\n",
      "[440]\tvalid_0's multi_error: 0.187568\n",
      "[450]\tvalid_0's multi_error: 0.187591\n",
      "[460]\tvalid_0's multi_error: 0.187411\n",
      "[470]\tvalid_0's multi_error: 0.187366\n",
      "[480]\tvalid_0's multi_error: 0.187426\n",
      "[490]\tvalid_0's multi_error: 0.187373\n",
      "[500]\tvalid_0's multi_error: 0.187321\n",
      "[510]\tvalid_0's multi_error: 0.187201\n",
      "[520]\tvalid_0's multi_error: 0.186931\n",
      "[530]\tvalid_0's multi_error: 0.186781\n",
      "[540]\tvalid_0's multi_error: 0.186736\n",
      "[550]\tvalid_0's multi_error: 0.186653\n",
      "[560]\tvalid_0's multi_error: 0.186736\n",
      "[570]\tvalid_0's multi_error: 0.186533\n",
      "[580]\tvalid_0's multi_error: 0.186368\n",
      "[590]\tvalid_0's multi_error: 0.186263\n",
      "[600]\tvalid_0's multi_error: 0.186218\n",
      "[610]\tvalid_0's multi_error: 0.186061\n",
      "[620]\tvalid_0's multi_error: 0.186091\n",
      "[630]\tvalid_0's multi_error: 0.186106\n",
      "[640]\tvalid_0's multi_error: 0.185926\n",
      "[650]\tvalid_0's multi_error: 0.185903\n",
      "[660]\tvalid_0's multi_error: 0.185836\n",
      "[670]\tvalid_0's multi_error: 0.185746\n",
      "[680]\tvalid_0's multi_error: 0.185746\n",
      "[690]\tvalid_0's multi_error: 0.185656\n",
      "[700]\tvalid_0's multi_error: 0.185566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[699]\tvalid_0's multi_error: 0.185536\n",
      "(666615, 58)\n",
      "(172402, 58)\n",
      "fold 2 \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's multi_error: 0.32757\n",
      "[20]\tvalid_0's multi_error: 0.214935\n",
      "[30]\tvalid_0's multi_error: 0.204397\n",
      "[40]\tvalid_0's multi_error: 0.200932\n",
      "[50]\tvalid_0's multi_error: 0.199296\n",
      "[60]\tvalid_0's multi_error: 0.198201\n",
      "[70]\tvalid_0's multi_error: 0.197444\n",
      "[80]\tvalid_0's multi_error: 0.196506\n",
      "[90]\tvalid_0's multi_error: 0.196139\n",
      "[100]\tvalid_0's multi_error: 0.195651\n",
      "[110]\tvalid_0's multi_error: 0.195366\n",
      "[120]\tvalid_0's multi_error: 0.195029\n",
      "[130]\tvalid_0's multi_error: 0.194331\n",
      "[140]\tvalid_0's multi_error: 0.193844\n",
      "[150]\tvalid_0's multi_error: 0.193529\n",
      "[160]\tvalid_0's multi_error: 0.193244\n",
      "[170]\tvalid_0's multi_error: 0.192914\n",
      "[180]\tvalid_0's multi_error: 0.192321\n",
      "[190]\tvalid_0's multi_error: 0.192081\n",
      "[200]\tvalid_0's multi_error: 0.191908\n",
      "[210]\tvalid_0's multi_error: 0.191578\n",
      "[220]\tvalid_0's multi_error: 0.191428\n",
      "[230]\tvalid_0's multi_error: 0.191286\n",
      "[240]\tvalid_0's multi_error: 0.191113\n",
      "[250]\tvalid_0's multi_error: 0.190753\n",
      "[260]\tvalid_0's multi_error: 0.190588\n",
      "[270]\tvalid_0's multi_error: 0.190536\n",
      "[280]\tvalid_0's multi_error: 0.190371\n",
      "[290]\tvalid_0's multi_error: 0.190153\n",
      "[300]\tvalid_0's multi_error: 0.190131\n",
      "[310]\tvalid_0's multi_error: 0.189891\n",
      "[320]\tvalid_0's multi_error: 0.189748\n",
      "[330]\tvalid_0's multi_error: 0.189606\n",
      "[340]\tvalid_0's multi_error: 0.189561\n",
      "[350]\tvalid_0's multi_error: 0.189336\n",
      "[360]\tvalid_0's multi_error: 0.189246\n",
      "[370]\tvalid_0's multi_error: 0.189036\n",
      "[380]\tvalid_0's multi_error: 0.189051\n",
      "[390]\tvalid_0's multi_error: 0.188953\n",
      "[400]\tvalid_0's multi_error: 0.188818\n",
      "[410]\tvalid_0's multi_error: 0.188728\n",
      "[420]\tvalid_0's multi_error: 0.188593\n",
      "[430]\tvalid_0's multi_error: 0.188541\n",
      "[440]\tvalid_0's multi_error: 0.188263\n",
      "[450]\tvalid_0's multi_error: 0.188203\n",
      "[460]\tvalid_0's multi_error: 0.188113\n",
      "[470]\tvalid_0's multi_error: 0.187971\n",
      "[480]\tvalid_0's multi_error: 0.187836\n",
      "[490]\tvalid_0's multi_error: 0.187678\n",
      "[500]\tvalid_0's multi_error: 0.187521\n",
      "[510]\tvalid_0's multi_error: 0.187453\n",
      "[520]\tvalid_0's multi_error: 0.187303\n",
      "[530]\tvalid_0's multi_error: 0.187258\n",
      "[540]\tvalid_0's multi_error: 0.187138\n",
      "[550]\tvalid_0's multi_error: 0.186921\n",
      "[560]\tvalid_0's multi_error: 0.189778\n",
      "[570]\tvalid_0's multi_error: 0.189711\n",
      "[580]\tvalid_0's multi_error: 0.189561\n",
      "[590]\tvalid_0's multi_error: 0.188413\n",
      "[600]\tvalid_0's multi_error: 0.187026\n",
      "[610]\tvalid_0's multi_error: 0.186816\n",
      "[620]\tvalid_0's multi_error: 0.186628\n",
      "[630]\tvalid_0's multi_error: 0.186576\n",
      "[640]\tvalid_0's multi_error: 0.186448\n",
      "[650]\tvalid_0's multi_error: 0.186298\n",
      "[660]\tvalid_0's multi_error: 0.186261\n",
      "[670]\tvalid_0's multi_error: 0.186291\n",
      "[680]\tvalid_0's multi_error: 0.186283\n",
      "[690]\tvalid_0's multi_error: 0.186208\n",
      "[700]\tvalid_0's multi_error: 0.186073\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[700]\tvalid_0's multi_error: 0.186073\n",
      "(666615, 58)\n",
      "(172402, 58)\n",
      "fold 3 \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's multi_error: 0.324649\n",
      "[20]\tvalid_0's multi_error: 0.21356\n",
      "[30]\tvalid_0's multi_error: 0.203515\n",
      "[40]\tvalid_0's multi_error: 0.200447\n",
      "[50]\tvalid_0's multi_error: 0.199194\n",
      "[60]\tvalid_0's multi_error: 0.198092\n",
      "[70]\tvalid_0's multi_error: 0.197356\n",
      "[80]\tvalid_0's multi_error: 0.196576\n",
      "[90]\tvalid_0's multi_error: 0.196089\n",
      "[100]\tvalid_0's multi_error: 0.195504\n",
      "[110]\tvalid_0's multi_error: 0.195174\n",
      "[120]\tvalid_0's multi_error: 0.194431\n",
      "[130]\tvalid_0's multi_error: 0.194011\n",
      "[140]\tvalid_0's multi_error: 0.193643\n",
      "[150]\tvalid_0's multi_error: 0.193313\n",
      "[160]\tvalid_0's multi_error: 0.192916\n",
      "[170]\tvalid_0's multi_error: 0.192661\n",
      "[180]\tvalid_0's multi_error: 0.192421\n",
      "[190]\tvalid_0's multi_error: 0.19194\n",
      "[200]\tvalid_0's multi_error: 0.191745\n",
      "[210]\tvalid_0's multi_error: 0.191445\n",
      "[220]\tvalid_0's multi_error: 0.191348\n",
      "[230]\tvalid_0's multi_error: 0.19107\n",
      "[240]\tvalid_0's multi_error: 0.19095\n",
      "[250]\tvalid_0's multi_error: 0.190793\n",
      "[260]\tvalid_0's multi_error: 0.190598\n",
      "[270]\tvalid_0's multi_error: 0.190328\n",
      "[280]\tvalid_0's multi_error: 0.19014\n",
      "[290]\tvalid_0's multi_error: 0.18984\n",
      "[300]\tvalid_0's multi_error: 0.189817\n",
      "[310]\tvalid_0's multi_error: 0.189615\n",
      "[320]\tvalid_0's multi_error: 0.189562\n",
      "[330]\tvalid_0's multi_error: 0.189405\n",
      "[340]\tvalid_0's multi_error: 0.18915\n",
      "[350]\tvalid_0's multi_error: 0.189112\n",
      "[360]\tvalid_0's multi_error: 0.189037\n",
      "[370]\tvalid_0's multi_error: 0.18885\n",
      "[380]\tvalid_0's multi_error: 0.18867\n",
      "[390]\tvalid_0's multi_error: 0.188632\n",
      "[400]\tvalid_0's multi_error: 0.188482\n",
      "[410]\tvalid_0's multi_error: 0.18843\n",
      "[420]\tvalid_0's multi_error: 0.18831\n",
      "[430]\tvalid_0's multi_error: 0.18819\n",
      "[440]\tvalid_0's multi_error: 0.187987\n",
      "[450]\tvalid_0's multi_error: 0.18798\n",
      "[460]\tvalid_0's multi_error: 0.187852\n",
      "[470]\tvalid_0's multi_error: 0.187582\n",
      "[480]\tvalid_0's multi_error: 0.187627\n",
      "[490]\tvalid_0's multi_error: 0.187387\n",
      "[500]\tvalid_0's multi_error: 0.187455\n",
      "[510]\tvalid_0's multi_error: 0.187297\n",
      "[520]\tvalid_0's multi_error: 0.187252\n",
      "[530]\tvalid_0's multi_error: 0.187049\n",
      "[540]\tvalid_0's multi_error: 0.186884\n",
      "[550]\tvalid_0's multi_error: 0.186772\n",
      "[560]\tvalid_0's multi_error: 0.186704\n",
      "[570]\tvalid_0's multi_error: 0.186644\n",
      "[580]\tvalid_0's multi_error: 0.186554\n",
      "[590]\tvalid_0's multi_error: 0.186554\n",
      "[600]\tvalid_0's multi_error: 0.186442\n",
      "[610]\tvalid_0's multi_error: 0.186224\n",
      "[620]\tvalid_0's multi_error: 0.186359\n",
      "[630]\tvalid_0's multi_error: 0.186074\n",
      "[640]\tvalid_0's multi_error: 0.186037\n",
      "[650]\tvalid_0's multi_error: 0.185909\n",
      "[660]\tvalid_0's multi_error: 0.185744\n",
      "[670]\tvalid_0's multi_error: 0.185767\n",
      "[680]\tvalid_0's multi_error: 0.185864\n",
      "[690]\tvalid_0's multi_error: 0.185699\n",
      "[700]\tvalid_0's multi_error: 0.185632\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[695]\tvalid_0's multi_error: 0.185579\n",
      "(666615, 58)\n",
      "(172402, 58)\n",
      "fold 4 \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[10]\tvalid_0's multi_error: 0.326039\n",
      "[20]\tvalid_0's multi_error: 0.214494\n",
      "[30]\tvalid_0's multi_error: 0.204419\n",
      "[40]\tvalid_0's multi_error: 0.201433\n",
      "[50]\tvalid_0's multi_error: 0.200023\n",
      "[60]\tvalid_0's multi_error: 0.198717\n",
      "[70]\tvalid_0's multi_error: 0.197697\n",
      "[80]\tvalid_0's multi_error: 0.196849\n",
      "[90]\tvalid_0's multi_error: 0.196587\n",
      "[100]\tvalid_0's multi_error: 0.195994\n",
      "[110]\tvalid_0's multi_error: 0.195379\n",
      "[120]\tvalid_0's multi_error: 0.195019\n",
      "[130]\tvalid_0's multi_error: 0.194501\n",
      "[140]\tvalid_0's multi_error: 0.194209\n",
      "[150]\tvalid_0's multi_error: 0.193788\n",
      "[160]\tvalid_0's multi_error: 0.193436\n",
      "[170]\tvalid_0's multi_error: 0.193083\n",
      "[180]\tvalid_0's multi_error: 0.192656\n",
      "[190]\tvalid_0's multi_error: 0.192461\n",
      "[200]\tvalid_0's multi_error: 0.192086\n",
      "[210]\tvalid_0's multi_error: 0.191793\n",
      "[220]\tvalid_0's multi_error: 0.191373\n",
      "[230]\tvalid_0's multi_error: 0.191103\n",
      "[240]\tvalid_0's multi_error: 0.190938\n",
      "[250]\tvalid_0's multi_error: 0.19081\n",
      "[260]\tvalid_0's multi_error: 0.190675\n",
      "[270]\tvalid_0's multi_error: 0.19045\n",
      "[280]\tvalid_0's multi_error: 0.19024\n",
      "[290]\tvalid_0's multi_error: 0.19012\n",
      "[300]\tvalid_0's multi_error: 0.18991\n",
      "[310]\tvalid_0's multi_error: 0.189677\n",
      "[320]\tvalid_0's multi_error: 0.189557\n",
      "[330]\tvalid_0's multi_error: 0.18943\n",
      "[340]\tvalid_0's multi_error: 0.189205\n",
      "[350]\tvalid_0's multi_error: 0.189055\n",
      "[360]\tvalid_0's multi_error: 0.188762\n",
      "[370]\tvalid_0's multi_error: 0.188672\n",
      "[380]\tvalid_0's multi_error: 0.188522\n",
      "[390]\tvalid_0's multi_error: 0.188425\n",
      "[400]\tvalid_0's multi_error: 0.18829\n",
      "[410]\tvalid_0's multi_error: 0.188065\n",
      "[420]\tvalid_0's multi_error: 0.187862\n",
      "[430]\tvalid_0's multi_error: 0.187779\n",
      "[440]\tvalid_0's multi_error: 0.187704\n",
      "[450]\tvalid_0's multi_error: 0.187832\n",
      "[460]\tvalid_0's multi_error: 0.187599\n",
      "[470]\tvalid_0's multi_error: 0.187599\n",
      "[480]\tvalid_0's multi_error: 0.187494\n",
      "[490]\tvalid_0's multi_error: 0.187247\n",
      "[500]\tvalid_0's multi_error: 0.187262\n",
      "[510]\tvalid_0's multi_error: 0.187239\n",
      "[520]\tvalid_0's multi_error: 0.187104\n",
      "[530]\tvalid_0's multi_error: 0.187074\n",
      "[540]\tvalid_0's multi_error: 0.186954\n",
      "[550]\tvalid_0's multi_error: 0.186819\n",
      "[560]\tvalid_0's multi_error: 0.186782\n",
      "[570]\tvalid_0's multi_error: 0.186812\n",
      "[580]\tvalid_0's multi_error: 0.186744\n",
      "[590]\tvalid_0's multi_error: 0.186684\n",
      "[600]\tvalid_0's multi_error: 0.186549\n",
      "[610]\tvalid_0's multi_error: 0.186489\n",
      "[620]\tvalid_0's multi_error: 0.186354\n",
      "[630]\tvalid_0's multi_error: 0.213098\n",
      "[640]\tvalid_0's multi_error: 0.239452\n",
      "[650]\tvalid_0's multi_error: 0.311508\n",
      "[660]\tvalid_0's multi_error: 0.392851\n",
      "[670]\tvalid_0's multi_error: 0.39147\n",
      "[680]\tvalid_0's multi_error: 0.383556\n",
      "[690]\tvalid_0's multi_error: 0.36913\n",
      "[700]\tvalid_0's multi_error: 0.351103\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[623]\tvalid_0's multi_error: 0.186309\n",
      "(666615, 58)\n",
      "(172402, 58)\n"
     ]
    }
   ],
   "source": [
    "#get number of feature and number of training rows\n",
    "X_train = train\n",
    "X_test = test\n",
    "\n",
    "del train, test \n",
    "\n",
    "num_train, num_feature = X_train.shape\n",
    "\n",
    "#Get parameters \n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'softmax',\n",
    "    'metric': 'multi_error',\n",
    "    'num_class':58,\n",
    "    'max_depth':20,\n",
    "    'num_leaves': 40,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 100,\n",
    "}\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "oof_preds = np.zeros((666615,58))\n",
    "sub_preds = np.zeros((172402, 58))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "feature_name = [col for col in X_train.columns]\n",
    "print(feature_name)\n",
    "print('Starting training...')\n",
    "print(X_train.shape)\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train,y)):\n",
    "    print('fold {} '.format(n_fold))\n",
    "    trn_x, trn_y = X_train[feature_name].iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_x, val_y = X_train[feature_name].iloc[val_idx], y.iloc[val_idx]\n",
    "    lgb_train = lgb.Dataset(trn_x, trn_y)\n",
    "    lgb_eval = lgb.Dataset(val_x, val_y)\n",
    "\n",
    "    gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "#                 num_boost_round = 2,\n",
    "                num_boost_round=700,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=100,\n",
    "                   verbose_eval=10)\n",
    "    \n",
    "    oof_preds[val_idx] += gbm.predict(val_x, num_iteration=gbm.best_iteration) #get oof prediction\n",
    "    print(oof_preds.shape)\n",
    "    #predict on test set, take average\n",
    "    sub_preds += gbm.predict(X_test[feature_name], num_iteration=gbm.best_iteration) / folds.n_splits \n",
    "    print (sub_preds.shape)\n",
    "    #save the feature important \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feature_name\n",
    "    fold_importance_df[\"importance\"] = np.log1p(gbm.feature_importance(\n",
    "        importance_type='gain',\n",
    "        iteration=gbm.best_iteration))\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "42749183dd0ac603503d9e74ff89019d3e60a511"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "      <th>class_3</th>\n",
       "      <th>class_4</th>\n",
       "      <th>class_5</th>\n",
       "      <th>class_6</th>\n",
       "      <th>class_7</th>\n",
       "      <th>class_8</th>\n",
       "      <th>class_9</th>\n",
       "      <th>class_10</th>\n",
       "      <th>class_11</th>\n",
       "      <th>class_12</th>\n",
       "      <th>class_13</th>\n",
       "      <th>class_14</th>\n",
       "      <th>class_15</th>\n",
       "      <th>class_16</th>\n",
       "      <th>class_17</th>\n",
       "      <th>class_18</th>\n",
       "      <th>class_19</th>\n",
       "      <th>class_20</th>\n",
       "      <th>class_21</th>\n",
       "      <th>class_22</th>\n",
       "      <th>class_23</th>\n",
       "      <th>class_24</th>\n",
       "      <th>class_25</th>\n",
       "      <th>class_26</th>\n",
       "      <th>class_27</th>\n",
       "      <th>class_28</th>\n",
       "      <th>class_29</th>\n",
       "      <th>class_30</th>\n",
       "      <th>class_31</th>\n",
       "      <th>class_32</th>\n",
       "      <th>class_33</th>\n",
       "      <th>class_34</th>\n",
       "      <th>class_35</th>\n",
       "      <th>class_36</th>\n",
       "      <th>class_37</th>\n",
       "      <th>class_38</th>\n",
       "      <th>class_39</th>\n",
       "      <th>class_40</th>\n",
       "      <th>class_41</th>\n",
       "      <th>class_42</th>\n",
       "      <th>class_43</th>\n",
       "      <th>class_44</th>\n",
       "      <th>class_45</th>\n",
       "      <th>class_46</th>\n",
       "      <th>class_47</th>\n",
       "      <th>class_48</th>\n",
       "      <th>class_49</th>\n",
       "      <th>class_50</th>\n",
       "      <th>class_51</th>\n",
       "      <th>class_52</th>\n",
       "      <th>class_53</th>\n",
       "      <th>class_54</th>\n",
       "      <th>class_55</th>\n",
       "      <th>class_56</th>\n",
       "      <th>class_57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370855998</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.044917</td>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.835339</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>4.808243e-06</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>4.933851e-08</td>\n",
       "      <td>7.974089e-07</td>\n",
       "      <td>2.976547e-07</td>\n",
       "      <td>2.544489e-07</td>\n",
       "      <td>6.393340e-08</td>\n",
       "      <td>7.584292e-08</td>\n",
       "      <td>4.236838e-08</td>\n",
       "      <td>8.034726e-08</td>\n",
       "      <td>3.989470e-07</td>\n",
       "      <td>6.489148e-07</td>\n",
       "      <td>4.044882e-07</td>\n",
       "      <td>1.662497e-07</td>\n",
       "      <td>2.115014e-07</td>\n",
       "      <td>4.642222e-08</td>\n",
       "      <td>1.020600e-06</td>\n",
       "      <td>5.997463e-07</td>\n",
       "      <td>4.650641e-07</td>\n",
       "      <td>4.364452e-07</td>\n",
       "      <td>1.664378e-06</td>\n",
       "      <td>4.391708e-06</td>\n",
       "      <td>4.041247e-07</td>\n",
       "      <td>1.446184e-07</td>\n",
       "      <td>1.349943e-07</td>\n",
       "      <td>4.748361e-09</td>\n",
       "      <td>4.085313e-07</td>\n",
       "      <td>7.030420e-08</td>\n",
       "      <td>1.926955e-06</td>\n",
       "      <td>5.445354e-08</td>\n",
       "      <td>2.145683e-07</td>\n",
       "      <td>1.676140e-08</td>\n",
       "      <td>5.811766e-07</td>\n",
       "      <td>1.089867e-08</td>\n",
       "      <td>2.152762e-08</td>\n",
       "      <td>1.762810e-08</td>\n",
       "      <td>8.626821e-08</td>\n",
       "      <td>4.335477e-08</td>\n",
       "      <td>2.702054e-07</td>\n",
       "      <td>2.366685e-08</td>\n",
       "      <td>1.047635e-09</td>\n",
       "      <td>2.995880e-09</td>\n",
       "      <td>7.390539e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>637234604</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.031456</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.041839</td>\n",
       "      <td>0.890569</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.911553e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4.061625e-09</td>\n",
       "      <td>1.661847e-07</td>\n",
       "      <td>6.311369e-08</td>\n",
       "      <td>1.813656e-08</td>\n",
       "      <td>9.835560e-09</td>\n",
       "      <td>6.249059e-09</td>\n",
       "      <td>9.773802e-10</td>\n",
       "      <td>2.580126e-08</td>\n",
       "      <td>7.004701e-08</td>\n",
       "      <td>5.392203e-08</td>\n",
       "      <td>1.108097e-07</td>\n",
       "      <td>4.787787e-08</td>\n",
       "      <td>4.479295e-08</td>\n",
       "      <td>1.153467e-08</td>\n",
       "      <td>7.195673e-08</td>\n",
       "      <td>6.990842e-08</td>\n",
       "      <td>4.861819e-08</td>\n",
       "      <td>5.662393e-08</td>\n",
       "      <td>1.111461e-07</td>\n",
       "      <td>1.341164e-06</td>\n",
       "      <td>9.956766e-09</td>\n",
       "      <td>1.556156e-08</td>\n",
       "      <td>3.567944e-09</td>\n",
       "      <td>2.394568e-10</td>\n",
       "      <td>3.870611e-08</td>\n",
       "      <td>1.306767e-08</td>\n",
       "      <td>8.790076e-08</td>\n",
       "      <td>4.194320e-09</td>\n",
       "      <td>8.526442e-08</td>\n",
       "      <td>1.313812e-09</td>\n",
       "      <td>6.216684e-08</td>\n",
       "      <td>1.255805e-09</td>\n",
       "      <td>1.028245e-08</td>\n",
       "      <td>2.059014e-09</td>\n",
       "      <td>1.740265e-08</td>\n",
       "      <td>2.137355e-09</td>\n",
       "      <td>2.125902e-09</td>\n",
       "      <td>2.910214e-09</td>\n",
       "      <td>8.677417e-10</td>\n",
       "      <td>7.608550e-11</td>\n",
       "      <td>4.802772e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690282890</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.033465</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.110529</td>\n",
       "      <td>0.835323</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.118492e-06</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>1.365760e-07</td>\n",
       "      <td>6.218940e-07</td>\n",
       "      <td>2.145429e-07</td>\n",
       "      <td>1.254660e-07</td>\n",
       "      <td>2.834860e-08</td>\n",
       "      <td>7.107559e-07</td>\n",
       "      <td>1.681893e-08</td>\n",
       "      <td>8.517255e-09</td>\n",
       "      <td>3.212414e-07</td>\n",
       "      <td>3.505192e-07</td>\n",
       "      <td>2.231795e-07</td>\n",
       "      <td>3.561056e-07</td>\n",
       "      <td>1.445951e-07</td>\n",
       "      <td>4.547634e-08</td>\n",
       "      <td>3.331032e-07</td>\n",
       "      <td>1.351771e-07</td>\n",
       "      <td>4.544003e-08</td>\n",
       "      <td>1.908759e-07</td>\n",
       "      <td>1.321776e-05</td>\n",
       "      <td>3.192979e-06</td>\n",
       "      <td>7.172879e-08</td>\n",
       "      <td>1.098006e-07</td>\n",
       "      <td>4.413486e-08</td>\n",
       "      <td>1.043498e-09</td>\n",
       "      <td>5.853772e-08</td>\n",
       "      <td>4.435656e-08</td>\n",
       "      <td>9.612162e-08</td>\n",
       "      <td>7.217265e-09</td>\n",
       "      <td>1.349682e-07</td>\n",
       "      <td>1.424652e-08</td>\n",
       "      <td>2.379910e-08</td>\n",
       "      <td>5.371527e-09</td>\n",
       "      <td>2.228502e-07</td>\n",
       "      <td>3.573852e-08</td>\n",
       "      <td>4.176700e-08</td>\n",
       "      <td>4.948529e-09</td>\n",
       "      <td>1.030882e-07</td>\n",
       "      <td>5.053217e-09</td>\n",
       "      <td>6.739011e-10</td>\n",
       "      <td>3.083631e-10</td>\n",
       "      <td>1.201587e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930913462</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.057847</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.037252</td>\n",
       "      <td>0.384195</td>\n",
       "      <td>0.328754</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.125021</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.315830e-05</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>4.019498e-07</td>\n",
       "      <td>1.021202e-05</td>\n",
       "      <td>9.511627e-06</td>\n",
       "      <td>4.421665e-07</td>\n",
       "      <td>3.866331e-07</td>\n",
       "      <td>3.333920e-07</td>\n",
       "      <td>2.036495e-07</td>\n",
       "      <td>3.498404e-07</td>\n",
       "      <td>5.910052e-07</td>\n",
       "      <td>1.336281e-06</td>\n",
       "      <td>1.501932e-06</td>\n",
       "      <td>4.309844e-07</td>\n",
       "      <td>1.717673e-07</td>\n",
       "      <td>1.188047e-07</td>\n",
       "      <td>5.449635e-07</td>\n",
       "      <td>3.849872e-07</td>\n",
       "      <td>2.281406e-07</td>\n",
       "      <td>1.675680e-07</td>\n",
       "      <td>3.856786e-07</td>\n",
       "      <td>4.884625e-07</td>\n",
       "      <td>1.871354e-07</td>\n",
       "      <td>2.853231e-08</td>\n",
       "      <td>1.256802e-07</td>\n",
       "      <td>2.350138e-09</td>\n",
       "      <td>1.007293e-06</td>\n",
       "      <td>2.128278e-07</td>\n",
       "      <td>3.773620e-07</td>\n",
       "      <td>3.336822e-07</td>\n",
       "      <td>2.420012e-07</td>\n",
       "      <td>2.489655e-08</td>\n",
       "      <td>7.962221e-07</td>\n",
       "      <td>2.205565e-08</td>\n",
       "      <td>1.141978e-06</td>\n",
       "      <td>3.959483e-08</td>\n",
       "      <td>9.232079e-08</td>\n",
       "      <td>7.553995e-09</td>\n",
       "      <td>4.362959e-08</td>\n",
       "      <td>6.632851e-08</td>\n",
       "      <td>3.528037e-09</td>\n",
       "      <td>5.289797e-10</td>\n",
       "      <td>5.085453e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039280071</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.037601</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.025048</td>\n",
       "      <td>0.910403</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.003669</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.889596e-07</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>7.305369e-09</td>\n",
       "      <td>5.720122e-07</td>\n",
       "      <td>4.924130e-08</td>\n",
       "      <td>3.707356e-08</td>\n",
       "      <td>1.709399e-08</td>\n",
       "      <td>1.667512e-08</td>\n",
       "      <td>1.004745e-08</td>\n",
       "      <td>3.023639e-08</td>\n",
       "      <td>1.967469e-07</td>\n",
       "      <td>1.259956e-07</td>\n",
       "      <td>6.517855e-08</td>\n",
       "      <td>4.940409e-08</td>\n",
       "      <td>5.605551e-08</td>\n",
       "      <td>1.328595e-08</td>\n",
       "      <td>4.589715e-08</td>\n",
       "      <td>1.125724e-07</td>\n",
       "      <td>1.354421e-08</td>\n",
       "      <td>6.350568e-08</td>\n",
       "      <td>1.331577e-07</td>\n",
       "      <td>3.322273e-07</td>\n",
       "      <td>1.527281e-08</td>\n",
       "      <td>3.108906e-08</td>\n",
       "      <td>3.877804e-09</td>\n",
       "      <td>9.121940e-11</td>\n",
       "      <td>2.154521e-07</td>\n",
       "      <td>1.426709e-08</td>\n",
       "      <td>9.953765e-08</td>\n",
       "      <td>2.471264e-09</td>\n",
       "      <td>4.012296e-08</td>\n",
       "      <td>3.387956e-09</td>\n",
       "      <td>2.798455e-08</td>\n",
       "      <td>1.542645e-09</td>\n",
       "      <td>1.217091e-08</td>\n",
       "      <td>1.011527e-09</td>\n",
       "      <td>2.353609e-07</td>\n",
       "      <td>1.314023e-09</td>\n",
       "      <td>3.571198e-08</td>\n",
       "      <td>2.052482e-09</td>\n",
       "      <td>3.993701e-10</td>\n",
       "      <td>2.198673e-10</td>\n",
       "      <td>1.107555e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid   class_0      ...           class_56      class_57\n",
       "0   370855998  0.001850      ...       2.995880e-09  7.390539e-10\n",
       "1   637234604  0.000178      ...       7.608550e-11  4.802772e-10\n",
       "2   690282890  0.002819      ...       3.083631e-10  1.201587e-09\n",
       "3   930913462  0.001192      ...       5.289797e-10  5.085453e-10\n",
       "4  1039280071  0.000261      ...       2.198673e-10  1.107555e-10\n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "bf37a070e556380e050670f3ab848cc0dcd4471a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 0.81374 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "oof_ = [np.argmax(preds) for preds in oof_preds]\n",
    "cv_score = accuracy_score(y, oof_)\n",
    "print(\"CV score: {:<8.5f}\".format(accuracy_score(y, oof_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "8301aa723a5ca4d3251b2c370c5ef1280a792a3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172402, 58)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "454db4b5e56f200eed37fa13000be609ee390410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving oof file\n",
      "finished saving pred file\n"
     ]
    }
   ],
   "source": [
    "np.save('oof_stacking_'+str(cv_score) +'.np',oof_preds)\n",
    "print('finished saving oof file')\n",
    "np.save('pred_stacking_'+str(cv_score) +'.np',sub_preds)\n",
    "print('finished saving pred file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "b14785b46a49bb332214ec2f93725e1c9a393c4d"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/ndsc-beginner/data_info_val_sample_submission.csv')\n",
    "y_te = [np.argmax(preds) for preds in sub_preds]\n",
    "submission['Category'] = y_te\n",
    "# submission['Category'] = sub_preds\n",
    "submission.to_csv('submission_stack.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "ccdc04489954dac2e77a5fddf0f85725c36ed942"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>370855998</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>637234604</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>690282890</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930913462</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1039280071</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemid  Category\n",
       "0   370855998         5\n",
       "1   637234604         5\n",
       "2   690282890         5\n",
       "3   930913462         4\n",
       "4  1039280071         5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "1439af18f9422e8e8e7b51443a2afa2c9fb93e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143243\n"
     ]
    }
   ],
   "source": [
    "print(143243)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
